"""API è·¯ç”±"""
import json
import uuid
from datetime import datetime
from pathlib import Path
from typing import List, Optional
import aiofiles
from fastapi import APIRouter, UploadFile, File, Form, Request, HTTPException, Query
from fastapi.responses import JSONResponse, FileResponse

import sys
sys.path.append(str(Path(__file__).parent.parent))

from db.database import create_checkin, get_checkins, add_like, get_liked_checkins, get_checkin_by_id
from utils.validators import (
    validate_email,
    validate_url,
    validate_qq,
    validate_nickname,
    validate_emoji,
    validate_content,
    validate_all_fields,
    sanitize_html,
    auto_review_content
)
from utils.security import (
    security_check,
    is_blocked_country,
    add_to_blacklist
)
from utils.archive_handler import (
    is_archive_file,
    validate_archive,
    extract_preview_images,
    ArchiveHandler
)


router = APIRouter(prefix="/api")

# æ–‡ä»¶ä¸Šä¼ é…ç½®
UPLOAD_DIR = Path(__file__).parent.parent / "static" / "uploads"
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
ALLOWED_EXTENSIONS = {
    "image": [".jpg", ".jpeg", ".png", ".gif", ".webp"],
    "video": [".mp4", ".webm", ".mov", ".avi"],
    "archive": [".zip", ".7z"]
}


def get_file_type(filename: str) -> str:
    """è·å–æ–‡ä»¶ç±»å‹"""
    ext = Path(filename).suffix.lower()
    if ext in ALLOWED_EXTENSIONS["image"]:
        return "image"
    elif ext in ALLOWED_EXTENSIONS["video"]:
        return "video"
    elif ext in ALLOWED_EXTENSIONS["archive"]:
        return "archive"
    return "unknown"


def is_allowed_file(filename: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å…è®¸ä¸Šä¼ """
    ext = Path(filename).suffix.lower()
    all_allowed = ALLOWED_EXTENSIONS["image"] + ALLOWED_EXTENSIONS["video"] + ALLOWED_EXTENSIONS["archive"]
    return ext in all_allowed


@router.post("/archive/fullimage")
async def get_archive_full_image(file: UploadFile = File(...), path: str = Form(...)):
    """è·å–å‹ç¼©åŒ…ä¸­æŸå¼ å›¾ç‰‡çš„å¤§å›¾é¢„è§ˆ"""
    # éªŒè¯æ–‡ä»¶ç±»å‹
    ext = Path(file.filename).suffix.lower()
    if ext not in ALLOWED_EXTENSIONS["archive"]:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": "åªæ”¯æŒ ZIP å’Œ 7Z æ ¼å¼"}
        )
    
    # è¯»å–æ–‡ä»¶å†…å®¹
    content = await file.read()
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    import tempfile
    with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as tmp:
        tmp.write(content)
        tmp_path = Path(tmp.name)
    
    try:
        handler = ArchiveHandler(tmp_path)
        full_image = handler.get_full_image(path)
        
        if full_image:
            return {"success": True, "image": full_image}
        else:
            return JSONResponse(
                status_code=400,
                content={"success": False, "message": "æ— æ³•è·å–å›¾ç‰‡"}
            )
    except Exception as e:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": f"è·å–å›¾ç‰‡å¤±è´¥: {str(e)}"}
        )
    finally:
        tmp_path.unlink(missing_ok=True)


@router.post("/archive/preview")
async def preview_archive(file: UploadFile = File(...)):
    """é¢„è§ˆå‹ç¼©åŒ…å†…å®¹ï¼ˆä¸ä¿å­˜æ–‡ä»¶ï¼Œä»…è¿”å›å›¾ç‰‡åˆ—è¡¨å’Œç¼©ç•¥å›¾ï¼‰"""
    # éªŒè¯æ–‡ä»¶ç±»å‹
    ext = Path(file.filename).suffix.lower()
    if ext not in ALLOWED_EXTENSIONS["archive"]:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": "åªæ”¯æŒ ZIP å’Œ 7Z æ ¼å¼"}
        )
    
    # è¯»å–æ–‡ä»¶å†…å®¹
    content = await file.read()
    file_size = len(content)
    
    # éªŒè¯æ–‡ä»¶å¤§å°
    if file_size > MAX_FILE_SIZE:
        size_mb = MAX_FILE_SIZE / 1024 / 1024
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": f"æ–‡ä»¶å¤§å°è¶…è¿‡{size_mb:.0f}MBé™åˆ¶"}
        )
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    import tempfile
    with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as tmp:
        tmp.write(content)
        tmp_path = Path(tmp.name)
    
    try:
        # éªŒè¯å‹ç¼©åŒ…ï¼ˆåŒ…å«æ¶æ„æ–‡ä»¶æ£€æµ‹ï¼‰
        is_valid, error_msg = validate_archive(tmp_path)
        if not is_valid:
            return JSONResponse(
                status_code=400,
                content={"success": False, "message": error_msg}
            )
        
        # è·å–å›¾ç‰‡åˆ—è¡¨
        handler = ArchiveHandler(tmp_path)
        image_list = handler.list_images()
        metadata = handler.get_metadata()
        
        # ç”Ÿæˆç¼©ç•¥å›¾ï¼ˆæœ€å¤š50å¼ ï¼‰
        images_with_thumbnails = handler.get_thumbnails(image_list, max_count=50)
        
        return {
            "success": True,
            "filename": file.filename,
            "size": file_size,
            "archive_info": {
                "image_count": len(image_list),
                "images": images_with_thumbnails,  # åŒ…å«ç¼©ç•¥å›¾
                "total_files": metadata.get("total_files", 0)
            }
        }
    except Exception as e:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": f"è§£æå‹ç¼©åŒ…å¤±è´¥: {str(e)}"}
        )
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        tmp_path.unlink(missing_ok=True)


@router.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """ä¸Šä¼ å•ä¸ªæ–‡ä»¶ï¼ˆæ”¯æŒå›¾ç‰‡ã€è§†é¢‘ã€å‹ç¼©åŒ…ï¼‰"""
    # éªŒè¯æ–‡ä»¶ç±»å‹
    if not is_allowed_file(file.filename):
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"}
        )
    
    # è¯»å–æ–‡ä»¶å†…å®¹
    content = await file.read()
    file_size = len(content)
    
    # éªŒè¯æ–‡ä»¶å¤§å°
    if file_size > MAX_FILE_SIZE:
        size_mb = MAX_FILE_SIZE / 1024 / 1024
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": f"æ–‡ä»¶å¤§å°è¶…è¿‡{size_mb:.0f}MBé™åˆ¶"}
        )
    
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    ext = Path(file.filename).suffix.lower()
    unique_filename = f"{uuid.uuid4()}{ext}"
    
    # æŒ‰å¹´æœˆç»„ç»‡ç›®å½•
    now = datetime.now()
    date_dir = UPLOAD_DIR / f"{now.year}-{now.month:02d}"
    
    file_type = get_file_type(file.filename)
    
    # å¦‚æœæ˜¯å‹ç¼©åŒ…ï¼Œä¿å­˜åˆ° archives å­ç›®å½•
    if file_type == "archive":
        date_dir = date_dir / "archives"
    
    date_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æ–‡ä»¶
    file_path = date_dir / unique_filename
    async with aiofiles.open(file_path, "wb") as f:
        await f.write(content)
    
    # è¿”å›ç›¸å¯¹è·¯å¾„
    if file_type == "archive":
        relative_path = f"/static/uploads/{now.year}-{now.month:02d}/archives/{unique_filename}"
    else:
        relative_path = f"/static/uploads/{now.year}-{now.month:02d}/{unique_filename}"
    
    result = {
        "success": True,
        "filename": unique_filename,
        "url": relative_path,
        "type": file_type
    }
    
    # å¦‚æœæ˜¯å‹ç¼©åŒ…ï¼Œåˆ—å‡ºå…¶ä¸­çš„å›¾ç‰‡æ–‡ä»¶
    if file_type == "archive":
        # éªŒè¯å‹ç¼©åŒ…
        is_valid, error_msg = validate_archive(file_path)
        if not is_valid:
            # åˆ é™¤æ— æ•ˆæ–‡ä»¶
            file_path.unlink(missing_ok=True)
            return JSONResponse(
                status_code=400,
                content={"success": False, "message": error_msg}
            )
        
        try:
            handler = ArchiveHandler(file_path)
            image_list = handler.list_images()
            result["archive_info"] = {
                "image_count": len(image_list),
                "images": image_list[:50]  # æœ€å¤šè¿”å›50ä¸ªå›¾ç‰‡æ–‡ä»¶å
            }
        except Exception as e:
            result["archive_info"] = {"error": str(e)}
    
    return result


@router.post("/checkin")
async def create_checkin_record(
    request: Request,
    content: str = Form(...),
    files: List[UploadFile] = File(default=[]),
    nickname: str = Form(default="ç”¨æˆ·0721"),
    email: Optional[str] = Form(default=None),
    qq: Optional[str] = Form(default=None),
    url: Optional[str] = Form(default=None),
    avatar: str = Form(default="ğŸ¥°"),
    # å‹ç¼©åŒ…é¢„è§ˆå›¾é€‰æ‹©ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰
    archive_preview_images: Optional[str] = Form(default=None),
    # èœœç½å­—æ®µï¼ˆæ­£å¸¸ç”¨æˆ·çœ‹ä¸åˆ°ï¼Œä¸ä¼šå¡«å†™ï¼‰
    website: Optional[str] = Form(default=None),  # honeypot
    form_token: Optional[str] = Form(default=None)  # è¡¨å•æ—¶é—´æˆ³
):
    """åˆ›å»ºæ‰“å¡è®°å½•"""
    # è·å–å®¢æˆ·ç«¯IP
    client_ip = request.client.host if request.client else None
    
    # === å®‰å…¨æ£€æŸ¥ ===
    is_allowed, status_code, error_msg = security_check(
        ip=client_ip or "unknown",
        action="write",
        content=content,
        honeypot_value=website,  # èœœç½å­—æ®µ
        form_timestamp=form_token
    )
    
    if not is_allowed:
        return JSONResponse(
            status_code=status_code,
            content={"success": False, "message": error_msg}
        )
    
    # === ç»¼åˆå­—æ®µå®‰å…¨éªŒè¯ ===
    is_valid, error_msg = validate_all_fields(
        content=content,
        nickname=nickname,
        email=email,
        qq=qq,
        url=url
    )
    if not is_valid:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": error_msg}
        )
    
    # éªŒè¯å†…å®¹
    is_valid, error_msg = validate_content(content)
    if not is_valid:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": error_msg}
        )
    
    # éªŒè¯æ˜µç§°
    is_valid, error_msg = validate_nickname(nickname)
    if not is_valid:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": error_msg}
        )
    
    # éªŒè¯é‚®ç®±
    is_valid, error_msg = validate_email(email)
    if not is_valid:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": error_msg}
        )
    
    # éªŒè¯ QQ å·
    is_valid, error_msg = validate_qq(qq)
    if not is_valid:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": error_msg}
        )
    
    # éªŒè¯ URL
    is_valid, error_msg = validate_url(url)
    if not is_valid:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": error_msg}
        )
    
    # éªŒè¯å¤´åƒ emoji
    is_valid, error_msg = validate_emoji(avatar)
    if not is_valid:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": error_msg}
        )
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    media_files = []
    archive_file_path = None
    archive_metadata_dict = None
    file_type_flag = "media"  # é»˜è®¤ä¸ºæ™®é€šåª’ä½“æ–‡ä»¶
    original_archive_name = None  # å‹ç¼©åŒ…åŸå§‹æ–‡ä»¶å
    archive_file_count = 0  # å‹ç¼©åŒ…æ–‡ä»¶æ•°é‡ï¼ˆä¸å«é¢„è§ˆå›¾ï¼‰
    
    for file in files:
        if file.filename:
            # ä¸Šä¼ æ–‡ä»¶
            upload_result = await upload_file(file)
            if isinstance(upload_result, dict) and upload_result.get("success"):
                media_files.append({
                    "url": upload_result["url"],
                    "type": upload_result["type"],
                    "filename": upload_result["filename"]
                })
                
                # å¦‚æœæ˜¯å‹ç¼©åŒ…ï¼Œè®°å½•è·¯å¾„å’ŒåŸå§‹æ–‡ä»¶å
                if upload_result["type"] == "archive":
                    file_type_flag = "archive"
                    original_archive_name = file.filename  # ä¿å­˜åŸå§‹æ–‡ä»¶å
                    archive_file_count = 1
                    # ä» URL æ„å»ºæ–‡ä»¶è·¯å¾„
                    archive_url = upload_result["url"]
                    archive_file_path = Path(__file__).parent.parent / archive_url.lstrip("/")
    
    # å¦‚æœæ˜¯å‹ç¼©åŒ…ï¼Œå¤„ç†é¢„è§ˆå›¾
    if file_type_flag == "archive" and archive_file_path and archive_file_path.exists():
        now = datetime.now()
        # ä¸ºè¿™ä¸ªæ‰“å¡è®°å½•åˆ›å»ºé¢„è§ˆå›¾ç›®å½•
        preview_dir = UPLOAD_DIR / f"{now.year}-{now.month:02d}" / "previews" / archive_file_path.stem
        
        # è§£æç”¨æˆ·é€‰æ‹©çš„é¢„è§ˆå›¾ï¼ˆå¦‚æœæœ‰ï¼‰
        selected_images = None
        if archive_preview_images:
            try:
                selected_images = json.loads(archive_preview_images)
            except:
                pass
        
        try:
            # æå–é¢„è§ˆå›¾
            preview_urls, metadata = extract_preview_images(
                archive_file_path,
                preview_dir,
                selected_images=selected_images,
                auto_select_count=3
            )
            
            # å°†é¢„è§ˆå›¾URLæ·»åŠ åˆ°media_files
            media_files.extend([
                {"url": url, "type": "preview", "filename": Path(url).name}
                for url in preview_urls
            ])
            
            # ä¿å­˜å…ƒæ•°æ®ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶å
            metadata["filename"] = original_archive_name or metadata.get("filename", "archive")
            archive_metadata_dict = metadata
            
        except Exception as e:
            print(f"æå–å‹ç¼©åŒ…é¢„è§ˆå›¾å¤±è´¥: {str(e)}")
    
    # å°†åª’ä½“æ–‡ä»¶åˆ—è¡¨è½¬ä¸ºJSONå­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆä»…ä¿å­˜URLï¼‰
    media_urls = [f["url"] for f in media_files]
    
    # å¤„ç†ç©ºå€¼ï¼ˆå¹¶è¿›è¡Œ HTML è½¬ä¹‰é˜²æ­¢ XSSï¼‰
    nickname = sanitize_html(nickname.strip()) if nickname and nickname.strip() else "ç”¨æˆ·0721"
    email = email.strip() if email and email.strip() else None
    qq = qq.strip() if qq and qq.strip() else None
    url = url.strip() if url and url.strip() else None
    avatar = avatar.strip() if avatar and avatar.strip() else "ğŸ¥°"
    content = sanitize_html(content.strip())  # å†…å®¹ä¹Ÿè½¬ä¹‰
    
    # === è‡ªåŠ¨å®¡æ ¸æ£€æµ‹ ===
    has_media = len(media_files) > 0
    auto_approved, review_reason = auto_review_content(
        content=content,
        has_media=has_media,
        nickname=nickname
    )
    
    # åˆ›å»ºæ‰“å¡è®°å½•
    checkin_id = create_checkin(
        content=content,
        media_files=media_urls,
        ip_address=client_ip,
        nickname=nickname,
        email=email,
        qq=qq,
        url=url,
        avatar=avatar,
        file_type=file_type_flag,
        archive_metadata=json.dumps(archive_metadata_dict) if archive_metadata_dict else None,
        approved=auto_approved
    )
    
    # æ ¹æ®å®¡æ ¸ç»“æœè¿”å›ä¸åŒçš„æ¶ˆæ¯
    if auto_approved:
        return {
            "success": True,
            "message": "æ‰“å¡æˆåŠŸ",
            "id": checkin_id,
            "media_count": archive_file_count if file_type_flag == "archive" else len(media_files)
        }
    else:
        return {
            "success": True,
            "message": "æäº¤æˆåŠŸï¼Œå†…å®¹éœ€è¦å®¡æ ¸åæ‰ä¼šæ˜¾ç¤º",
            "id": checkin_id,
            "media_count": archive_file_count if file_type_flag == "archive" else len(media_files),
            "pending_review": True
        }


@router.get("/checkins")
async def get_checkin_list(
    request: Request,
    page: int = Query(default=1, ge=1),
    limit: int = Query(default=20, ge=1, le=100),
    sort: str = Query(default="desc", pattern="^(asc|desc)$"),
    sort_by: str = Query(default="id", pattern="^(id|love)$"),
    nickname: Optional[str] = Query(default=None),
    email: Optional[str] = Query(default=None),
    content: Optional[str] = Query(default=None),
    exclude_default_nickname: bool = Query(default=False),
    min_content_length: Optional[int] = Query(default=None, ge=0)
):
    """è·å–æ‰“å¡è®°å½•åˆ—è¡¨ï¼ˆæ”¯æŒæœç´¢å’Œç­›é€‰ï¼‰
    
    Args:
        page: é¡µç 
        limit: æ¯é¡µæ•°é‡
        sort: æ’åºæ–¹å¼ (asc=æ­£åº, desc=å€’åº)
        sort_by: æ’åºå­—æ®µ (id=æŒ‰ID, love=æŒ‰ç‚¹èµæ•°)
        nickname: æ˜µç§°ï¼ˆæ¨¡ç³Šæœç´¢ï¼‰
        email: é‚®ç®±ï¼ˆç²¾ç¡®æœç´¢ï¼‰
        content: å†…å®¹å…³é”®è¯ï¼ˆæ¨¡ç³Šæœç´¢ï¼‰
        exclude_default_nickname: æ’é™¤é»˜è®¤æ˜µç§°ç”¨æˆ·
        min_content_length: æœ€å°å†…å®¹é•¿åº¦
    """
    # è·å–å®¢æˆ·ç«¯ IP
    client_ip = request.client.host if request.client else None
    
    # å®‰å…¨æ£€æŸ¥ï¼ˆè¯»å–æ“ä½œï¼‰
    is_allowed, status_code, error_msg = security_check(
        ip=client_ip or "unknown",
        action="read"
    )
    
    if not is_allowed:
        return JSONResponse(
            status_code=status_code,
            content={"success": False, "message": error_msg}
        )
    
    checkins, total = get_checkins(
        page=page,
        limit=limit,
        sort_order=sort,
        sort_by=sort_by,
        nickname=nickname,
        email=email,
        content_keyword=content,
        exclude_default_nickname=exclude_default_nickname,
        min_content_length=min_content_length
    )
    
    # è·å–å½“å‰ç”¨æˆ·å·²ç‚¹èµçš„è®°å½•
    client_ip = request.client.host if request.client else None
    liked_ids = get_liked_checkins(client_ip) if client_ip else []
    
    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    checkin_list = []
    for checkin in checkins:
        checkin_dict = checkin.to_dict()
        # è§£æ media_files JSON å­—ç¬¦ä¸²
        checkin_dict["media_files"] = json.loads(checkin_dict["media_files"])
        # æ·»åŠ æ˜¯å¦å·²ç‚¹èµæ ‡è®°
        checkin_dict["liked"] = checkin.id in liked_ids
        checkin_list.append(checkin_dict)
    
    return {
        "success": True,
        "data": checkin_list,
        "total": total,
        "page": page,
        "limit": limit,
        "pages": (total + limit - 1) // limit
    }


@router.post("/like/{checkin_id}")
async def like_checkin(checkin_id: int, request: Request):
    """ç»™è®°å½•ç‚¹èµ
    
    Args:
        checkin_id: è®°å½•ID
    """
    client_ip = request.client.host if request.client else None
    
    if not client_ip:
        return JSONResponse(
            status_code=400,
            content={"success": False, "message": "æ— æ³•è·å–æ‚¨çš„IPåœ°å€"}
        )
    
    success, love_count, message = add_like(checkin_id, client_ip)
    
    return {
        "success": success,
        "message": message,
        "love": love_count,
        "liked": True if success else None  # æˆåŠŸæ—¶æ ‡è®°ä¸ºå·²ç‚¹èµ
    }


@router.get("/download/{checkin_id}")
async def download_archive(checkin_id: int):
    """ä¸‹è½½æ‰“å¡è®°å½•çš„å‹ç¼©åŒ…
    
    Args:
        checkin_id: è®°å½•ID
    """
    # è·å–æ‰“å¡è®°å½•
    checkin = get_checkin_by_id(checkin_id)
    
    if not checkin:
        raise HTTPException(status_code=404, detail="è®°å½•ä¸å­˜åœ¨")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºå‹ç¼©åŒ…ç±»å‹
    if checkin.file_type != "archive":
        raise HTTPException(status_code=400, detail="è¯¥è®°å½•ä¸åŒ…å«å‹ç¼©åŒ…")
    
    # è§£æ media_files æ‰¾åˆ°å‹ç¼©åŒ…æ–‡ä»¶
    try:
        media_files = json.loads(checkin.media_files)
    except:
        raise HTTPException(status_code=500, detail="æ•°æ®æ ¼å¼é”™è¯¯")
    
    # æ‰¾åˆ°å‹ç¼©åŒ…æ–‡ä»¶
    archive_url = None
    for url in media_files:
        if '/archives/' in url and (url.endswith('.zip') or url.endswith('.7z')):
            archive_url = url
            break
    
    if not archive_url:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°å‹ç¼©åŒ…æ–‡ä»¶")
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    file_path = Path(__file__).parent.parent / archive_url.lstrip("/")
    
    if not file_path.exists():
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    
    # è·å–åŸå§‹æ–‡ä»¶åï¼ˆä»å…ƒæ•°æ®ä¸­ï¼‰
    original_filename = file_path.name
    if checkin.archive_metadata:
        try:
            metadata = json.loads(checkin.archive_metadata)
            original_filename = metadata.get("filename", file_path.name)
        except:
            pass
    
    # è¿”å›æ–‡ä»¶ä¸‹è½½
    return FileResponse(
        path=file_path,
        filename=original_filename,
        media_type='application/octet-stream'
    )

